# Ermögliche vollständiges Crawling für Google, Ahrefs und Semrush
User-agent: Googlebot
Allow: /

User-agent: AhrefsBot
Allow: /

User-agent: SemrushBot
Allow: /

# Allgemeine Richtlinien für alle anderen Bots
User-agent: *
Allow: /

# Blockiere den Zugriff auf bestimmte sensible Verzeichnisse und Dateien
Disallow: /cgi-bin/
Disallow: /private/
Disallow: /tmp/
Disallow: /logs/
Disallow: /secret/
Disallow: /admin/  # Beispiel für ein Admin-Verzeichnis
Disallow: /config.php  # Beispiel für eine spezifische PHP-Datei, die nicht gecrawlt werden soll
Disallow: /db_backup.php  # Beispiel für eine Datei, die nicht gecrawlt werden soll

# Erlaube das Crawlen von allen anderen PHP-Seiten
Allow: /*.php$

# Erlaube das Crawlen aller CSS, JS und Bilddateien (wichtig für das korrekte Rendering in den Suchergebnissen)
Allow: /*.css$
Allow: /*.js$
Allow: /*.jpg$
Allow: /*.jpeg$
Allow: /*.png$
Allow: /*.gif$
Allow: /*.webp$
Allow: /*.svg$
Allow: /*.json$
Allow: /*.webp$
Allow: /*.ico$
Allow: /*.xml$

# Erlaube den Zugriff auf die Sitemap
Sitemap: https://www.webdesign-alcor.at/sitemap.xml

# Crawl-Delay für Bots, die dies unterstützen (falls nötig)
Crawl-Delay: 10


